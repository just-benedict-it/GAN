{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_MNIST.ipynb",
      "provenance": [],
      "mount_file_id": "1yNtGY7dxOHfKZzEEX6sIGE4NTHB8OJHn",
      "authorship_tag": "ABX9TyPIPBHLJ+82dRIkw7bY3ahN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/just-benedict-it/GAN/blob/main/GAN_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "zlpq71kRs4QE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm.auto import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cpu\")\n",
        "print(\"using: \", DEVICE)\n",
        "\n",
        "EPOCHS = 400\n",
        "BATCH_SIZE = 200"
      ],
      "metadata": {
        "id": "ntmoKTTwtX-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from six.moves import urllib\n",
        "opener = urllib.request.build_opener()\n",
        "opener.addheaders = [(\"User-agent\", \"Mozila/5.0\")]"
      ],
      "metadata": {
        "id": "-KbmwxP_udf7"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = transforms.Compose([\n",
        "                                  transforms.ToTensor(),\n",
        "                                  transforms.Normalize((0.5,),(0.5,))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root=\"/content/drive/MyDrive/MNIST\", train=True,\n",
        "                                      download=True, transform=transformer)\n",
        "\n",
        "#DataLoder: loader에 전체 trainset을 담고 BATCH_SIZE만큼씩 내보내주는 저장소 역할\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "testset = torchvision.datasets.MNIST(root=\"/content/drive/MyDrive/MNIST\", train=False,\n",
        "                                     download=True, transform=transformer)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "_7nyjbZPHTqs"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#200개이미지가 담겨있는 trainloader를 iter돌림\n",
        "#next는 iter중 다음 것 하나만 보여준다.\n",
        "sample, label = next(iter(trainloader))\n",
        "\n",
        "def imshow_grid(img):\n",
        "    img = torchvision.utils.make_grid(img.cpu().detach())\n",
        "    img = (img + 1)/2\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
        "    ax = plt.gca()\n",
        "    #matplotlib사용할 때 나오는 좌표계를 보일거냐 안 보일거냐\n",
        "    ax.axes.xaxis.set_visible(False)\n",
        "    ax.axes.yaxis.set_visible(True)\n",
        "    plt.show()\n",
        "\n",
        "imshow_grid(sample[0:8])\n"
      ],
      "metadata": {
        "id": "QefOB5HlHToL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dis_model(nn.Module):\n",
        "    def __init__(self, image_size, hidden_space):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Linear(image_size, hidden_space),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_space, hidden_space),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_space, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, input_x):\n",
        "        x = self.features(input_x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "WzlscfJ8HTjw"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Gen_model(nn.Module):\n",
        "    def __init__(self, latent_space, hidden_space, image_size):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Linear(latent_space, hidden_space),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_space, hidden_space),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_space, image_size),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "    def forward(self, input_x):\n",
        "        x = self.features(input_x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "ArubUGBzNohQ"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im_size = 784\n",
        "hidden_size = 256\n",
        "latent_size = 100\n",
        "\n",
        "Dis_net = Dis_model(image_size = im_size, hidden_space = hidden_size).to(DEVICE)\n",
        "# Dis_net = Dis_model(im_size, hidden_size).to(DEVICE)\n",
        "Gen_net = Gen_model(latent_space=latent_size, hidden_space=hidden_size, image_size=im_size).to(DEVICE)\n",
        "\n",
        "d_optimizer = optim.Adam(Dis_net.parameters(), lr=0.0002)\n",
        "g_optimizer = optim.Adam(Gen_net.parameters(), lr=0.0002)"
      ],
      "metadata": {
        "id": "KhVwVl-FHTg5"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(generator, discriminator, train_loader, optimizer_d, optimizer_g):\n",
        "    generator.train()\n",
        "    discriminator.train()\n",
        "\n",
        "    for data, target in train_loader:\n",
        "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "\n",
        "        optimizer_d.zero_grad()\n",
        "        noise_sample_d = torch.randn(BATCH_SIZE, latent_size).to(DEVICE)\n",
        "\n",
        "        discri_value = discriminator(data.view(-1,28*28))\n",
        "        loss_real = -1 * torch.log(discri_value)\n",
        "\n",
        "        gene_value = discriminator(generator(noise_sample_d))\n",
        "        loss_fake = -1 * torch.log(1 - gene_value)\n",
        "\n",
        "        loss_d = (loss_real + loss_fake).mean()\n",
        "\n",
        "        loss_d.backward()\n",
        "        optimizer_d.step()\n",
        "\n",
        "        optimizer_g.zero_grad()\n",
        "        noise_sample_g = torch.randn(BATCH_SIZE, latent_size).to(DEVICE)\n",
        "\n",
        "        fake_value = discriminator(generator(noise_sample_g))\n",
        "        loss_generator = -1 * torch.log(fake_value).mean()\n",
        "\n",
        "        loss_generator.backward()\n",
        "        optimizer_g.step()\n"
      ],
      "metadata": {
        "id": "z7uR48_3HTXD"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in tqdm(range(EPOCHS)):\n",
        "    train(Gen_net, Dis_net, trainloader, d_optimizer, g_optimizer)\n",
        "\n",
        "    if (epoch+1)%20 == 0:\n",
        "        print(\"epoch %i /400\" % (epoch+1))\n",
        "        noise_sam = torch.randn(16, latent_size).to(DEVICE)\n",
        "        imshow_grid(Gen_net(noise_sam).view(-1,1,28,28))\n",
        "        print(\"\\n\")\n"
      ],
      "metadata": {
        "id": "nY8wGUEUmgOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_noise = torch.randn(16, latent_size).to(DEVICE)\n",
        "imshow_grid(Gen_net(sample_noise).view(-1,1,28,28))"
      ],
      "metadata": {
        "id": "7VxoRIF3f31T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}